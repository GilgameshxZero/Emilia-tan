<!DOCTYPE html>
    <html>
    <head><meta charset="utf-8"/></head><body><template>
        <h1 id="iclr-2021-keynote---geometric-deep-learning-the-erlangen-programme-of-ml---m-bronstein">ICLR 2021 Keynote - “Geometric Deep Learning: The Erlangen Programme of ML” - M Bronstein</h1>
<p>October 23, 2021<br>
<a href="https://www.youtube.com/watch?v=w6Pw4MOzMuo">https://www.youtube.com/watch?v=w6Pw4MOzMuo</a></p>
<p>Erlangen: unifying framework.</p>
<p>GDL aims to provide a unifying framework for good ML ideas and architectures. By analyzing the structure of the input data, can establish equivarance and invariance.</p>
<p>An equivariant transformation is not affected by symmetries in the input; an invariant transformation is.</p>
<ul>
<li>Convolutional layers are equivariant.</li>
<li>Pooling layers are invariant.</li>
</ul>
<p>Similar synonyms can be found in transformers/attention, as well as GNNs. Thus, the equivariant/invariant structure is strong and indicative of good ideas in ML.</p>
<p>Commonly, input structures are some sort of manifold; thus equivariance on manifolds is important, as well as determining the manifold structure of the input.</p>

        
        
    </template></body>
    </html>